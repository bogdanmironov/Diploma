{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import json\n",
    "import shutil\n",
    "from tensorflow.keras.layers import Dropout, Dense, Flatten\n",
    "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "\n",
    "np.random.seed(1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "train_file = 'MA0035_4_m8_train.h5'\n",
    "test_file = 'MA0035_4_m8_test.h5'\n",
    "\n",
    "h5_train = h5py.File(train_file, 'r')\n",
    "h5_test = h5py.File(test_file, 'r')\n",
    "\n",
    "train_data = h5_train['data'][:90000]\n",
    "train_binlabels = h5_train['binlabels'][:90000]\n",
    "\n",
    "val_data = h5_train['data'][-10000:]\n",
    "val_binlabels = h5_train['binlabels'][-10000:]\n",
    "\n",
    "test_data = h5_test['data'][:]\n",
    "test_binlabels = h5_test['binlabels'][:]\n",
    "\n",
    "train_data = tf.cast(train_data, dtype=tf.float32)\n",
    "train_labels = tf.cast(train_binlabels, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15512\n"
     ]
    }
   ],
   "source": [
    "x = 0\n",
    "for i in train_binlabels:\n",
    "    if i == 1:\n",
    "        x=x+1\n",
    "        \n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90000, 4, 1000)\n",
      "(90000, 1000, 4)\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape)\n",
    "train_data_T = np.transpose(train_data, axes=(0, 2, 1))\n",
    "print(train_data_T.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 4, 1000)\n",
      "(10000, 1000, 4)\n"
     ]
    }
   ],
   "source": [
    "print(test_data.shape)\n",
    "test_data_T = np.transpose(test_data, axes=(0, 2, 1))\n",
    "print(test_data_T.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 4, 1000)\n",
      "(10000, 1000, 4)\n"
     ]
    }
   ],
   "source": [
    "print(val_data.shape)\n",
    "val_data_T = np.transpose(val_data, axes=(0, 2, 1))\n",
    "print(val_data_T.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(hyperparameters, log_dir):\n",
    "    board_log = log_dir + '/board'\n",
    "    hparams_log = log_dir + '/hparams.json'\n",
    "\n",
    "    my_callbacks = [\n",
    "        TensorBoard(log_dir=board_log),\n",
    "        EarlyStopping('val_loss', patience=100)\n",
    "    ]\n",
    "\n",
    "    with open(hparams_log, 'w') as hparam_file:\n",
    "        json.dump(hyperparameters, hparam_file)\n",
    "\n",
    "    model = tf.keras.models.Sequential(\n",
    "        [\n",
    "            Flatten(input_shape=(1000, 4)),\n",
    "            Dropout(hyperparameters['l0_dropout_rate']),\n",
    "            Dense(100, activation='relu', kernel_regularizer='l2', bias_regularizer='l2'),\n",
    "            Dropout(0.5),\n",
    "            Dense(30, activation='relu'),\n",
    "            Dropout(0.6),\n",
    "            Dense(30, activation='relu', kernel_regularizer='l2', bias_regularizer='l2'),\n",
    "            Dense(5, activation='relu'),\n",
    "            Dense(1, activation=tf.keras.activations.sigmoid)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    with tf.device('/GPU:0'):\n",
    "        model.compile(\n",
    "            optimizer = tf.keras.optimizers.Adam(learning_rate=hyperparameters['learning_rate']),\n",
    "            loss = tf.keras.losses.BinaryCrossentropy(),\n",
    "            metrics=[tf.keras.metrics.AUC(name='auc')],\n",
    "        )\n",
    "\n",
    "        history = model.fit(train_data_T, train_binlabels,\n",
    "                epochs=hyperparameters['epochs'], \n",
    "                validation_data=(val_data_T, val_binlabels),\n",
    "                batch_size=hyperparameters['batch_size'],\n",
    "                callbacks=my_callbacks,\n",
    "                shuffle=True)\n",
    "\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_and_save_roc(false_positive_rate, true_positive_rate, log_dir):\n",
    "    roc = plt.figure(0)\n",
    "\n",
    "    plt.plot(false_positive_rate, true_positive_rate, color='darkorange', label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], color='navy', linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic example')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "\n",
    "    plt.savefig(log_dir + '/roc.pdf')\n",
    "    pickle.dump(roc, open((log_dir + '/pickle/roc.fig.pickle'), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_and_save_loss(history, log_dir):\n",
    "    loss = plt.figure(1)\n",
    "    history_loss = history.history['loss']\n",
    "    history_val_loss = history.history['val_loss']\n",
    "    epochs = range(len(history_loss))\n",
    "\n",
    "    plt.plot(epochs, history_loss, 'ko', label='Training loss')\n",
    "    plt.plot(epochs, history_val_loss, 'b', label='Validation loss')\n",
    "    plt.ylim([0.0, 1.5])\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.savefig(log_dir + '/loss.pdf')\n",
    "    pickle.dump(loss, open((log_dir + '/pickle/loss.fig.pickle'), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_and_save_auc(history, log_dir):\n",
    "    auc = plt.figure(2)\n",
    "\n",
    "    history_auc = history.history['auc']\n",
    "    history_val_auc = history.history['val_auc']\n",
    "    epochs = range(len(history_auc))\n",
    "\n",
    "    plt.plot(epochs, history_auc, 'ko', label='Training auc')\n",
    "    plt.plot(epochs, history_val_auc, 'b', label='Validation auc')\n",
    "    plt.title('Training and validation auc')\n",
    "    plt.ylim(0.46, 1.0)\n",
    "    plt.legend()\n",
    "\n",
    "    plt.savefig(log_dir + '/auc.pdf')\n",
    "    pickle.dump(auc, open((log_dir + '/pickle/auc.fig.pickle'), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'shutil' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-5d25c7939966>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrmtree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'shutil' is not defined"
     ]
    }
   ],
   "source": [
    "L0_DROPOUT_RATES = [0.0]\n",
    "BATCH_SIZE = [32, 64, 128, 254, 512]\n",
    "LEARNING_RATE = [0.0000023]\n",
    "\n",
    "for l0_dropout_rate in L0_DROPOUT_RATES:\n",
    "    log_dir = './logs/4_h_layer_test/:' + str(l0_dropout_rate) + '|hu100l2|dr0.5|hu30|dr0.6|hu30l2|hu5lr' + str(LEARNING_RATE[0])\n",
    "\n",
    "    try:\n",
    "        shutil.rmtree(log_dir)\n",
    "    except OSError as e:\n",
    "        print(e)\n",
    "\n",
    "    try:\n",
    "        os.makedirs(log_dir)\n",
    "        os.makedirs(log_dir + '/pickle')\n",
    "    except OSError as e:\n",
    "        print(e)\n",
    "\n",
    "    hparams = {\n",
    "        'l0_dropout_rate': l0_dropout_rate,\n",
    "        'learning_rate': LEARNING_RATE[0],\n",
    "        'batch_size': BATCH_SIZE[2],\n",
    "        'epochs': 300,\n",
    "    }\n",
    "\n",
    "    model, history = train_model(hparams, log_dir)\n",
    "\n",
    "    acc, auc = model.evaluate(test_data_T, test_binlabels)\n",
    "    yhat = model.predict(test_data)\n",
    "    fpr, tpr, _ = roc_curve(test_binlabels, yhat)\n",
    "    roc_auc = roc_auc_score(test_binlabels, yhat)\n",
    "\n",
    "    plot_and_save_roc(fpr, tpr, log_dir)\n",
    "    plot_and_save_loss(history, log_dir)\n",
    "    plot_and_save_auc(history, log_dir)\n",
    "\n",
    "    plt.show()\n",
    "    model.save(log_dir + '/model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit",
   "language": "python",
   "name": "python38564bit27940071741648109a666d4d70900ef3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}